{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T18:59:14.858481Z",
     "start_time": "2018-09-12T18:59:14.308143Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T18:59:14.900030Z",
     "start_time": "2018-09-12T18:59:14.861776Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stitch(stack, numpix_threshold=0):\n",
    "    '''\n",
    "    Combine multiple instance segmentations based on overlapping patches into a single\n",
    "    segmentation\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "        stack : np.ndarray\n",
    "            first two dimensions of stack should be the dimensions of the input image,\n",
    "            and the third dimension be the number of overlapping patches\n",
    "        numpix_threshold : int\n",
    "            a label will be retained in the output only if it has at least \n",
    "            numpix_threshold pixels\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        result : numpy.ndarray\n",
    "            a 2-D array labels\n",
    "    '''\n",
    "    from scipy.sparse.csgraph import csgraph_from_dense, connected_components\n",
    "    \n",
    "    # find foreground labels\n",
    "    nonzero_idx = np.any(stack,axis=2)\n",
    "    \n",
    "    # get unique label combinations across patches in stack\n",
    "    labels_to_combine = np.unique(stack[nonzero_idx],axis=0)\n",
    "    \n",
    "    # compute a \"connectivity matrix\" that indicates which labels overlap across patches\n",
    "    conn_mat = np.zeros((labels_to_combine.max()+1,labels_to_combine.max()+1), dtype='bool')\n",
    "    \n",
    "    for row, label_combo in enumerate(labels_to_combine):\n",
    "        group = label_combo[np.nonzero(label_combo)]\n",
    "        for i in range(len(group)-1):\n",
    "            for j in range(i+1,len(group)):\n",
    "                conn_mat[group[i], group[j]] = True\n",
    "                conn_mat[group[j], group[i]] = True\n",
    "\n",
    "    #np.fill_diagonal(conn_mat, True)\n",
    "    \n",
    "    # find connected components using this connectivity matrix\n",
    "    # each connected component will be a different label in the result (as long as it\n",
    "    # contains the minimum required number of pixels)\n",
    "    graph = csgraph_from_dense(conn_mat)\n",
    "    n_conncomp, graph_complabels = connected_components(graph, directed=False)\n",
    "    \n",
    "    result = np.zeros_like(stack[:,:,0])\n",
    "    \n",
    "    # reassign labels to the ids of the connected components\n",
    "    for label in np.unique(stack):\n",
    "        # get 2-D mask of voxels with a given label\n",
    "        mask = np.any(stack==label,axis=2)\n",
    "        \n",
    "        # make sure that there are enough many pixels\n",
    "        if mask.sum() > numpix_threshold:\n",
    "            # if so, reassign this label to its corresponding connected component id\n",
    "            result[np.any(stack==label,axis=2)] = graph_complabels[label]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def stitch_sparse(stack, numpix_threshold=0):\n",
    "    '''\n",
    "    Combine multiple instance segmentations based on overlapping patches into a single\n",
    "    segmentation. This implementation uses a sparse instead of a dense connectivity matrix,\n",
    "    so could be helpful if there is a large number of objects being segmented.\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "        stack : numpy.ndarray\n",
    "            first two dimensions of stack should be the dimensions of the input image,\n",
    "            and the third dimension be the number of overlapping patches\n",
    "        numpix_threshold : int\n",
    "            a label will be retained in the output only if it has at least \n",
    "            numpix_threshold pixels\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        result : numpy.ndarray\n",
    "            a 2-D array labels\n",
    "    '''\n",
    "    from scipy.sparse import csr_matrix\n",
    "    from scipy.sparse.csgraph import connected_components\n",
    "    \n",
    "    # get label combinations across stacks\n",
    "    nonzero_idx = np.any(stack,axis=2)\n",
    "    labels_to_combine = stack[nonzero_idx]  \n",
    "    \n",
    "    # keep track of the number of times a label combination occurs\n",
    "    combo_dict = {}\n",
    "    for row, label_combo in enumerate(labels_to_combine):\n",
    "        group = label_combo[np.nonzero(label_combo)]\n",
    "        for i in range(len(group)):\n",
    "            for j in range(i+1,len(group)):\n",
    "                if (group[i], group[j]) in combo_dict:\n",
    "                    combo_dict[(group[i], group[j])] += 1\n",
    "                else:\n",
    "                    combo_dict[(group[i], group[j])] = 1\n",
    "                       \n",
    "    conn_mat = csr_matrix((np.ones(len(combo_dict), dtype='bool'),\n",
    "                           ([key[0] for key in combo_dict.keys()], \n",
    "                            [key[1] for key in combo_dict.keys()])),\n",
    "                          shape=(labels_to_combine.max()+1,labels_to_combine.max()+1))\n",
    "    \n",
    "    n_conncomp, graph_complabels = connected_components(conn_mat, directed=False)\n",
    "    \n",
    "    result = np.zeros_like(stack[:,:,0])\n",
    "\n",
    "    for label in np.unique(stack):\n",
    "        mask = np.any(stack==label,axis=2)\n",
    "        if mask.sum() > numpix_threshold:\n",
    "            result[np.any(stack==label,axis=2)] = graph_complabels[label]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def fix_euler_numbers(result, max_hole_size=999):\n",
    "    '''\n",
    "    Fix labels whose Euler numbers are not 1 (i.e., labels with holes or handles)\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "        result : numpy.ndarray\n",
    "            2-D integer array of labeled objects\n",
    "        max_hole_size : int\n",
    "            max number of pixels to fill\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        result : numpy.ndarray\n",
    "    '''\n",
    "    from skimage.measure import regionprops\n",
    "    from skimage.morphology import remove_small_holes\n",
    "    \n",
    "    # use skimage's regionprops to get the Euler number for each object\n",
    "    props = regionprops(result)\n",
    "    labels = np.array([roi['label'] for roi in props])\n",
    "    euler_numbers = np.array([roi['euler_number'] for roi in props])\n",
    "    \n",
    "    for bad_label in labels[euler_numbers!=1]:\n",
    "        mask = remove_small_holes(result==bad_label, area_threshold=max_hole_size)\n",
    "        \n",
    "        # if there are other labels that intersect with the holes that were filled,\n",
    "        # then those other labels will be removed from the image\n",
    "        result[np.isin(result,np.setdiff1d(np.unique(result[mask]),[0, bad_label]))] = 0\n",
    "        result[mask] = bad_label\n",
    "    \n",
    "    return result\n",
    "\n",
    "def split_large_objects(result, stack):\n",
    "    '''\n",
    "    Detect objects that are too large\n",
    "    Determine whether these are actually single or multiple objects\n",
    "    If multiple objects, manipulate labels accordingly\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "        result : numpy.ndarray\n",
    "            2-D integer array of labeled objects\n",
    "        stack : np.ndarray\n",
    "            stack that was used to generate result\n",
    "            first two dimensions of stack should be the dimensions of the input image,\n",
    "            and the third dimension be the number of overlapping patches\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        result : numpy.ndarray\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference-sparce-512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T18:59:15.939906Z",
     "start_time": "2018-09-12T18:59:15.908676Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = np.load('../inference-sparce-512/inference-bigger-cell.npy')\n",
    "stack = stack[:,:,1:]\n",
    "npix = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T18:59:56.500987Z",
     "start_time": "2018-09-12T18:59:16.283727Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bilgelm/anaconda/envs/python3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "result = stitch(stack, numpix_threshold=npix)\n",
    "result = fix_euler_numbers(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T19:00:35.674520Z",
     "start_time": "2018-09-12T18:59:56.502858Z"
    }
   },
   "outputs": [],
   "source": [
    "result_sparse = stitch_sparse(stack, numpix_threshold=npix)\n",
    "result_sparse = fix_euler_numbers(result_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T19:00:35.733306Z",
     "start_time": "2018-09-12T19:00:35.676397Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image.fromarray(result).save('../inference-sparce-512/result_hackathon.tif')\n",
    "Image.fromarray(result_sparse).save('../inference-sparce-512/result_sparse_hackathon.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference-dense-512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T19:06:22.236651Z",
     "start_time": "2018-09-12T19:06:22.157305Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = np.load('../inference-dense-512/inference-stack.npy')\n",
    "stack = stack[:,:,1:]\n",
    "\n",
    "npix = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T19:09:28.355553Z",
     "start_time": "2018-09-12T19:06:27.225167Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = stitch(stack, numpix_threshold=npix)\n",
    "result = fix_euler_numbers(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T19:09:28.420869Z",
     "start_time": "2018-09-12T19:09:28.357425Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image.fromarray(result).save('../inference-dense-512/result_hackathon.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference-dense-512 using flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T19:20:26.229553Z",
     "start_time": "2018-09-12T19:20:26.174347Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stack = np.load('../inference-dense-512/inference-bigger-cell-after-flipping.npy')\n",
    "stack = stack[:,:,1:]\n",
    "\n",
    "npix = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T19:23:25.156415Z",
     "start_time": "2018-09-12T19:20:26.384777Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = stitch(stack, numpix_threshold=npix)\n",
    "result = fix_euler_numbers(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T19:23:25.179197Z",
     "start_time": "2018-09-12T19:23:25.157984Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image.fromarray(result).save('../inference-dense-512/result_flipped_hackathon.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T16:42:37.426462Z",
     "start_time": "2018-09-12T16:42:37.423793Z"
    }
   },
   "source": [
    "# inference-dense-512 using both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T19:23:37.399411Z",
     "start_time": "2018-09-12T19:23:37.140908Z"
    }
   },
   "outputs": [],
   "source": [
    "stack = np.load('../inference-dense-512/inference-stack.npy')\n",
    "stack = stack[:,:,1:]\n",
    "\n",
    "stack_flipped = np.load('../inference-dense-512/inference-bigger-cell-after-flipping.npy')\n",
    "stack_flipped = stack_flipped[:,:,1:]\n",
    "\n",
    "stack_flipped[stack_flipped>0] += stack.max() # ensure that IDs are different \n",
    "\n",
    "stack = np.concatenate((stack,stack_flipped), axis=2)\n",
    "\n",
    "npix = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T19:29:21.718155Z",
     "start_time": "2018-09-12T19:23:37.937291Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = stitch(stack, numpix_threshold=npix)\n",
    "result = fix_euler_numbers(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-12T19:29:21.812745Z",
     "start_time": "2018-09-12T19:29:21.719819Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image.fromarray(result).save('../inference-dense-512/result_both_hackathon.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3.6]",
   "language": "python",
   "name": "conda-env-python3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
